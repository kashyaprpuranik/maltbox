# =============================================================================
# Data Plane Infrastructure Services
# =============================================================================
#
# Modes:
#   standalone: No control plane, use static config only
#   connected:  Use control plane API, fall back to static config
#
# Usage:
#   Standard mode (gVisor - RECOMMENDED for production):
#     docker-compose --profile standard up -d
#     Requires gVisor: https://gvisor.dev/docs/user_guide/install/
#
#   Development mode (no gVisor - for local dev or if gVisor unavailable):
#     docker-compose --profile dev up -d
#
#   With local admin UI:
#     docker-compose --profile standard --profile admin up -d
#     Open http://localhost:8080
#
#   With auditing (log forwarding):
#     docker-compose --profile standard --profile auditing up -d
#
#   With SSH tunnel:
#     docker-compose --profile standard --profile ssh up -d
#
# Network Architecture:
#   agent-net (isolated, internal)
#     └── agent: can ONLY reach envoy + dns-filter
#
#   infra-net (can reach control plane)
#     └── envoy, dns-filter (bridged to agent-net)
#     └── fluent-bit (log forwarding) - optional
#
# Security Controls:
#   - Agent has no direct internet/CP access (IP bypass prevention)
#   - Credential injection handled by Envoy Lua filter
#   - Only Envoy and fluent-bit can reach control plane
#
# =============================================================================

version: '3.8'

services:
  # ===========================================================================
  # Agent Container (DEVELOPMENT - runc runtime, no gVisor)
  # Use when gVisor is not installed or for local development
  # For production, use --profile standard (gVisor) instead
  # ===========================================================================
  agent-dev:
    build:
      context: .
      dockerfile: agent.Dockerfile
      args:
        - VARIANT=${AGENT_VARIANT:-lean}
    image: agent:${AGENT_VARIANT:-lean}
    container_name: agent
    profiles:
      - dev

    # Standard container runtime (no gVisor)
    runtime: runc

    # Security hardening
    security_opt:
      - no-new-privileges:true
      # Block raw sockets to prevent proxy bypass via packet crafting
      - seccomp:./configs/seccomp/agent-profile.json

    # Resource limits
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
          pids: 256
        reservations:
          cpus: '0.5'
          memory: 512M

    # DNS forced through dns-filter
    dns:
      - 172.30.0.5

    # Environment
    environment:
      - HTTP_PROXY=http://172.30.0.10:8443
      - HTTPS_PROXY=http://172.30.0.10:8443
      - NO_PROXY=localhost,127.0.0.1
      - USER_NAME=agent
      # SSH public keys (paste your public key here or mount file)
      - SSH_AUTHORIZED_KEYS=${SSH_AUTHORIZED_KEYS:-}
      # Tmux session settings
      - TMUX_AUTO_ATTACH=${TMUX_AUTO_ATTACH:-1}  # Set to 0 to disable auto-attach
      - TMUX_SESSION=${TMUX_SESSION:-main}       # Default session name

    # Volumes
    volumes:
      - agent-logs:/var/log/agent
      - agent-workspace:/workspace
      # Optional: mount SSH keys file
      # - ./ssh-keys:/ssh-keys:ro

    # ONLY on agent-net - cannot reach infra-net or external directly
    networks:
      agent-net:
        ipv4_address: 172.30.0.20

    # Capture output to Docker logs (read by fluent-bit)
    logging:
      driver: json-file
      options:
        max-size: "100m"
        max-file: "5"

    depends_on:
      - envoy
      - dns-filter

    restart: unless-stopped

  # ===========================================================================
  # Agent Container (STANDARD - gVisor isolation, recommended for production)
  # Requires gVisor: https://gvisor.dev/docs/user_guide/install/
  # Use --profile dev if gVisor is not installed
  # ===========================================================================
  agent:
    build:
      context: .
      dockerfile: agent.Dockerfile
      args:
        - VARIANT=${AGENT_VARIANT:-lean}
    image: agent:${AGENT_VARIANT:-lean}
    container_name: agent
    profiles:
      - standard

    # gVisor runtime - syscalls intercepted in user-space
    runtime: runsc

    # Strict security options
    security_opt:
      - no-new-privileges:true
      - seccomp:unconfined  # gVisor provides its own syscall filtering

    # Stricter resource limits for secure mode
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 2G
          pids: 128
        reservations:
          cpus: '0.25'
          memory: 256M

    # DNS forced through dns-filter
    dns:
      - 172.30.0.5

    # Environment
    environment:
      - HTTP_PROXY=http://172.30.0.10:8443
      - HTTPS_PROXY=http://172.30.0.10:8443
      - NO_PROXY=localhost,127.0.0.1
      - USER_NAME=agent
      - SSH_AUTHORIZED_KEYS=${SSH_AUTHORIZED_KEYS:-}
      - TMUX_AUTO_ATTACH=${TMUX_AUTO_ATTACH:-1}
      - TMUX_SESSION=${TMUX_SESSION:-main}

    # Volumes (more restricted in secure mode)
    volumes:
      - agent-logs:/var/log/agent
      - agent-workspace:/workspace:rw

    # ONLY on agent-net
    networks:
      agent-net:
        ipv4_address: 172.30.0.20

    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "3"

    depends_on:
      - envoy
      - dns-filter

    restart: unless-stopped

  # ===========================================================================
  # DNS Filter - CoreDNS with domain allowlist
  # Bridged to both networks so agent can resolve DNS
  # Corefile generated by agent-manager from CP allowlist + static config
  # ===========================================================================
  dns-filter:
    image: coredns/coredns:latest
    container_name: dns-filter

    volumes:
      # Generated Corefile (written by agent-manager)
      - coredns-config:/etc/coredns
      # Static Corefile as initial fallback (until agent-manager syncs)
      - ./configs/coredns/Corefile:/etc/coredns/Corefile.default:ro
      # Static allowlist as fallback
      - ./configs/coredns/allowlist.hosts:/etc/coredns/static-allowlist.hosts:ro

    # Use generated Corefile, fall back to default if not present
    command: ["-conf", "/etc/coredns/Corefile"]

    # On BOTH networks - agent-net for agent access, infra-net for upstream
    networks:
      agent-net:
        ipv4_address: 172.30.0.5
      infra-net:
        ipv4_address: 172.31.0.5

    restart: unless-stopped

  # ===========================================================================
  # Envoy Proxy - Egress gateway with logging and credential injection
  # Config generated by agent-manager from maltbox.yaml
  # ===========================================================================
  envoy:
    image: envoyproxy/envoy:v1.28-latest
    container_name: envoy-proxy

    volumes:
      # Generated config from agent-manager (falls back to static if not present)
      - envoy-config:/etc/envoy
      # Static config as fallback (copied by entrypoint if no generated config)
      - ./configs/envoy/envoy-enhanced.yaml:/etc/envoy/envoy.default.yaml:ro
      # Entrypoint script
      - ./configs/envoy/entrypoint.sh:/entrypoint.sh:ro

    entrypoint: ["/bin/sh", "/entrypoint.sh"]

    environment:
      # Operation mode: "standalone" or "connected"
      - DATAPLANE_MODE=${DATAPLANE_MODE:-standalone}
      # Control plane authentication token (for connected mode Lua filter)
      - CONTROL_PLANE_TOKEN=${CONTROL_PLANE_TOKEN:-}

    # JSON logs to stdout (captured by Docker, read by fluent-bit)
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "3"

    # On BOTH networks - agent-net for agent access, infra-net for egress + CP access
    networks:
      agent-net:
        ipv4_address: 172.30.0.10
      infra-net:
        ipv4_address: 172.31.0.10

    restart: unless-stopped

    healthcheck:
      test: ["CMD-SHELL", "wget -qO- http://localhost:9901/ready || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 3

  # ===========================================================================
  # Vector - Log Collection & Forwarding to ClickHouse
  # Collects Docker logs, gVisor audit logs, agent app logs
  # Optional: Only runs with --profile auditing
  # ===========================================================================
  vector:
    image: timberio/vector:0.36.0-alpine
    container_name: vector
    profiles:
      - auditing

    volumes:
      - ./configs/vector/vector.yaml:/etc/vector/vector.yaml:ro
      - agent-logs:/var/log/agent:ro
      - vector-data:/var/lib/vector
      - vector-backup:/var/log/vector
      # Docker socket for container log collection
      - /var/run/docker.sock:/var/run/docker.sock:ro
      # gVisor logs (requires runsc --debug-log=/var/log/runsc/)
      - /var/log/runsc:/var/log/runsc:ro

    environment:
      # OpenObserve connection (control plane)
      - OPENOBSERVE_HOST=${OPENOBSERVE_HOST}
      - OPENOBSERVE_PORT=${OPENOBSERVE_PORT:-5080}
      - OPENOBSERVE_USER=${OPENOBSERVE_USER:-admin@maltbox.local}
      - OPENOBSERVE_PASSWORD=${OPENOBSERVE_PASSWORD:-admin}
      # Metadata
      - AGENT_ID=${AGENT_ID:-default}
      - ENVIRONMENT=${ENVIRONMENT:-development}

    command: ["--config", "/etc/vector/vector.yaml"]

    # Only on infra-net - can reach control plane
    networks:
      - infra-net

    restart: unless-stopped

    healthcheck:
      test: ["CMD", "vector", "top", "--interval", "1"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ===========================================================================
  # Agent Manager - Watches maltbox.yaml and regenerates configs
  # Optional: Only needed if you want dynamic config updates
  # For static configs, edit coredns/Corefile and envoy/envoy.yaml directly
  # ===========================================================================
  agent-manager:
    build:
      context: ./services
      dockerfile: agent-manager/Dockerfile
    container_name: agent-manager
    profiles:
      - managed
      - admin  # Admin UI benefits from agent-manager for config reload

    environment:
      - AGENT_CONTAINER_NAME=agent
      - AGENT_WORKSPACE_VOLUME=data-plane_agent-workspace
      # Operation mode: "standalone" or "connected"
      - DATAPLANE_MODE=${DATAPLANE_MODE:-standalone}
      # Control plane connection (for connected mode)
      - CONTROL_PLANE_URL=${CONTROL_PLANE_URL}
      - CONTROL_PLANE_TOKEN=${CONTROL_PLANE_TOKEN}
      - HEARTBEAT_INTERVAL=${HEARTBEAT_INTERVAL:-30}
      - AGENT_ID=${AGENT_ID:-default}
      # Config paths
      - MALTBOX_CONFIG_PATH=/etc/maltbox/maltbox.yaml
      - COREDNS_COREFILE_PATH=/etc/coredns/Corefile
      - ENVOY_CONFIG_PATH=/etc/envoy/envoy.yaml
      - CONFIG_SYNC_INTERVAL=${CONFIG_SYNC_INTERVAL:-300}
      # Container names for reload
      - COREDNS_CONTAINER_NAME=dns-filter
      - ENVOY_CONTAINER_NAME=envoy-proxy
      # Legacy (for backwards compatibility)
      - COREDNS_ALLOWLIST_PATH=/etc/coredns/allowlist.hosts
      - STATIC_ALLOWLIST_PATH=/etc/coredns/static-allowlist.hosts

    volumes:
      # Docker socket for container management
      - /var/run/docker.sock:/var/run/docker.sock:ro
      # Main config file (source of truth)
      - ./configs/maltbox.yaml:/etc/maltbox/maltbox.yaml:ro
      # CoreDNS config volume (agent-manager writes generated config here)
      - coredns-config:/etc/coredns
      # Envoy config volume (agent-manager writes generated config here)
      - envoy-config:/etc/envoy
      # Static allowlist as fallback
      - ./configs/coredns/allowlist.hosts:/etc/coredns/static-allowlist.hosts:ro

    # No ports exposed - polling-based, outbound only
    networks:
      - infra-net

    restart: unless-stopped

  # ===========================================================================
  # Local Admin UI - Web interface for standalone mode
  # Provides config editing, container management, and log viewing
  # Optional: Only runs with --profile admin
  # ===========================================================================
  local-admin:
    build:
      context: ./services/local-admin
      dockerfile: Dockerfile
    container_name: local-admin
    profiles:
      - admin

    environment:
      - MALTBOX_CONFIG_PATH=/etc/maltbox/maltbox.yaml
      - AGENT_CONTAINER_NAME=agent
      - COREDNS_CONTAINER_NAME=dns-filter
      - ENVOY_CONTAINER_NAME=envoy-proxy
      - FRPC_CONTAINER_NAME=frpc
      - DATA_PLANE_DIR=/app/data-plane

    volumes:
      # Docker socket for container management
      - /var/run/docker.sock:/var/run/docker.sock
      # Config file (read/write)
      - ./configs/maltbox.yaml:/etc/maltbox/maltbox.yaml
      # Data plane directory (for .env and docker-compose access)
      - .:/app/data-plane

    ports:
      - "${LOCAL_ADMIN_PORT:-8080}:8080"

    networks:
      - infra-net

    restart: unless-stopped

  # ===========================================================================
  # FRP Client - Reverse tunnel for SSH access via STCP
  # Connects outbound to control plane FRP server
  # STCP mode: P2P tunneling with unique secret key per agent
  # Optional: Only runs with --profile ssh
  # ===========================================================================
  frpc:
    image: snowdreamtech/frpc:latest
    container_name: frpc
    profiles:
      - ssh

    environment:
      - FRP_SERVER_ADDR=${FRP_SERVER_ADDR}
      - FRP_SERVER_PORT=${FRP_SERVER_PORT:-7000}
      - FRP_AUTH_TOKEN=${FRP_AUTH_TOKEN}
      - AGENT_ID=${AGENT_ID:-default}
      - STCP_SECRET_KEY=${STCP_SECRET_KEY}  # Unique per agent, from control plane API

    volumes:
      - ./configs/frpc/frpc.toml:/etc/frp/frpc.toml:ro

    # On BOTH networks:
    # - agent-net: to reach agent SSH (172.30.0.20:22)
    # - infra-net: to reach FRP server (outbound)
    networks:
      agent-net:
        ipv4_address: 172.30.0.30
      infra-net:
        ipv4_address: 172.31.0.30

    depends_on:
      - agent

    restart: unless-stopped

# =============================================================================
# Networks
# =============================================================================
networks:
  # Agent network - INTERNAL, no external access
  agent-net:
    driver: bridge
    internal: true  # No external connectivity
    enable_ipv6: false  # Prevent IPv6 bypass of egress controls
    ipam:
      config:
        - subnet: 172.30.0.0/16

  # Infrastructure network - can reach control plane
  infra-net:
    driver: bridge
    enable_ipv6: false  # Prevent IPv6 bypass of egress controls
    ipam:
      config:
        - subnet: 172.31.0.0/16

# =============================================================================
# Volumes
# =============================================================================
volumes:
  agent-logs:
  agent-workspace:
  coredns-config:
  envoy-config:
  vector-data:
  vector-backup:

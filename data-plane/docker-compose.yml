# =============================================================================
# Data Plane Infrastructure Services
# =============================================================================
#
# Modes:
#   standalone: No control plane, use static config only
#   connected:  Use control plane API, fall back to static config
#
# Usage:
#   Connected mode (default):
#     docker-compose up -d
#
#   Standalone mode (no control plane, no auditing):
#     docker-compose up -d
#
#   With auditing (fluent-bit):
#     docker-compose --profile auditing up -d
#
# Network Architecture:
#   agent-net (isolated, internal)
#     └── agent: can ONLY reach envoy + dns-filter
#
#   infra-net (can reach control plane)
#     └── envoy, dns-filter (bridged to agent-net)
#     └── fluent-bit (log forwarding) - optional
#
# Security Controls:
#   - Agent has no direct internet/CP access (IP bypass prevention)
#   - Credential injection handled by Envoy Lua filter
#   - Only Envoy and fluent-bit can reach control plane
#
# =============================================================================

version: '3.8'

services:
  # ===========================================================================
  # Agent Container (isolated - can only reach envoy and dns-filter)
  # ===========================================================================
  agent:
    build:
      context: .
      dockerfile: agent.Dockerfile
      args:
        - VARIANT=${AGENT_VARIANT:-lean}
    image: agent:${AGENT_VARIANT:-lean}
    container_name: agent

    # Container runtime: "runc" (default) or "runsc" (gVisor)
    # gVisor provides kernel-level isolation - agent syscalls never reach host kernel
    # Install gVisor: https://gvisor.dev/docs/user_guide/install/
    runtime: ${CONTAINER_RUNTIME:-runc}

    # Security hardening (relaxed for SSH - runs as root to start sshd, then drops to user)
    security_opt:
      - no-new-privileges:true

    # Resource limits
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
          pids: 256
        reservations:
          cpus: '0.5'
          memory: 512M

    # DNS forced through dns-filter
    dns:
      - 172.30.0.5

    # Environment
    environment:
      - HTTP_PROXY=http://172.30.0.10:8443
      - HTTPS_PROXY=http://172.30.0.10:8443
      - NO_PROXY=localhost,127.0.0.1
      - USER_NAME=agent
      # SSH public keys (paste your public key here or mount file)
      - SSH_AUTHORIZED_KEYS=${SSH_AUTHORIZED_KEYS:-}

    # Volumes
    volumes:
      - agent-logs:/var/log/agent
      - agent-workspace:/workspace
      # Optional: mount SSH keys file
      # - ./ssh-keys:/ssh-keys:ro

    # ONLY on agent-net - cannot reach infra-net or external directly
    networks:
      agent-net:
        ipv4_address: 172.30.0.20

    # Capture output to Docker logs (read by fluent-bit)
    logging:
      driver: json-file
      options:
        max-size: "100m"
        max-file: "5"

    depends_on:
      - envoy
      - dns-filter

    restart: unless-stopped

  # ===========================================================================
  # DNS Filter - CoreDNS with domain allowlist
  # Bridged to both networks so agent can resolve DNS
  # Corefile generated by agent-manager from CP allowlist + static config
  # ===========================================================================
  dns-filter:
    image: coredns/coredns:latest
    container_name: dns-filter

    volumes:
      # Generated Corefile (written by agent-manager)
      - coredns-config:/etc/coredns
      # Static Corefile as initial fallback (until agent-manager syncs)
      - ./configs/coredns/Corefile:/etc/coredns/Corefile.default:ro
      # Static allowlist as fallback
      - ./configs/coredns/allowlist.hosts:/etc/coredns/static-allowlist.hosts:ro

    # Use generated Corefile, fall back to default if not present
    command: ["-conf", "/etc/coredns/Corefile"]

    # On BOTH networks - agent-net for agent access, infra-net for upstream
    networks:
      agent-net:
        ipv4_address: 172.30.0.5
      infra-net:
        ipv4_address: 172.31.0.5

    restart: unless-stopped

  # ===========================================================================
  # Envoy Proxy - Egress gateway with logging and credential injection
  # Credential injection is handled via Lua filter calling control plane API
  # ===========================================================================
  envoy:
    image: envoyproxy/envoy:v1.28-latest
    container_name: envoy-proxy

    volumes:
      - ./configs/envoy/envoy-enhanced.yaml:/etc/envoy/envoy.yaml:ro

    environment:
      # Operation mode: "standalone" or "connected"
      - DATAPLANE_MODE=${DATAPLANE_MODE:-connected}
      # Control plane authentication token (generate with: openssl rand -hex 32)
      - CONTROL_PLANE_TOKEN=${CONTROL_PLANE_TOKEN:-}
      # Static configuration (used as fallback or in standalone mode)
      # Format: domain:header_name:header_value|domain:header_name:header_value
      - STATIC_CREDENTIALS=${STATIC_CREDENTIALS:-}
      # Format: domain:rpm:burst,domain:rpm:burst
      - STATIC_RATE_LIMITS=${STATIC_RATE_LIMITS:-default:120:20}

    # JSON logs to stdout (captured by Docker, read by fluent-bit)
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "3"

    # On BOTH networks - agent-net for agent access, infra-net for egress + CP access
    networks:
      agent-net:
        ipv4_address: 172.30.0.10
      infra-net:
        ipv4_address: 172.31.0.10

    restart: unless-stopped

    healthcheck:
      test: ["CMD-SHELL", "wget -qO- http://localhost:9901/ready || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 3

  # ===========================================================================
  # Vector - Log Collection & Forwarding to ClickHouse
  # Collects Docker logs, gVisor audit logs, agent app logs
  # Optional: Only runs with --profile auditing
  # ===========================================================================
  vector:
    image: timberio/vector:0.36.0-alpine
    container_name: vector
    profiles:
      - auditing

    volumes:
      - ./configs/vector/vector.yaml:/etc/vector/vector.yaml:ro
      - agent-logs:/var/log/agent:ro
      - vector-data:/var/lib/vector
      - vector-backup:/var/log/vector
      # Docker socket for container log collection
      - /var/run/docker.sock:/var/run/docker.sock:ro
      # gVisor logs (requires runsc --debug-log=/var/log/runsc/)
      - /var/log/runsc:/var/log/runsc:ro

    environment:
      # OpenObserve connection (control plane)
      - OPENOBSERVE_HOST=${OPENOBSERVE_HOST}
      - OPENOBSERVE_PORT=${OPENOBSERVE_PORT:-5080}
      - OPENOBSERVE_USER=${OPENOBSERVE_USER:-admin@maltbox.local}
      - OPENOBSERVE_PASSWORD=${OPENOBSERVE_PASSWORD:-admin}
      # Metadata
      - AGENT_ID=${AGENT_ID:-default}
      - ENVIRONMENT=${ENVIRONMENT:-development}

    command: ["--config", "/etc/vector/vector.yaml"]

    # Only on infra-net - can reach control plane
    networks:
      - infra-net

    restart: unless-stopped

    healthcheck:
      test: ["CMD", "vector", "top", "--interval", "1"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ===========================================================================
  # Agent Manager - Container lifecycle management (wipe, restart, status)
  # Polls control plane for commands - no inbound ports required
  # Also syncs allowlist from CP to CoreDNS
  # ===========================================================================
  agent-manager:
    build:
      context: ./services/agent-manager
      dockerfile: Dockerfile
    container_name: agent-manager

    environment:
      - AGENT_CONTAINER_NAME=agent
      - AGENT_WORKSPACE_VOLUME=data-plane_agent-workspace
      # Control plane connection (for heartbeat polling)
      - CONTROL_PLANE_URL=${CONTROL_PLANE_URL}
      - CONTROL_PLANE_TOKEN=${CONTROL_PLANE_TOKEN}
      - HEARTBEAT_INTERVAL=${HEARTBEAT_INTERVAL:-30}
      - AGENT_ID=${AGENT_ID:-default}
      # Allowlist sync config
      - ALLOWLIST_SYNC_INTERVAL=${ALLOWLIST_SYNC_INTERVAL:-300}
      - COREDNS_ALLOWLIST_PATH=/etc/coredns/allowlist.hosts
      - COREDNS_COREFILE_PATH=/etc/coredns/Corefile
      - STATIC_ALLOWLIST_PATH=/etc/coredns/static-allowlist.hosts
      - COREDNS_CONTAINER_NAME=dns-filter

    volumes:
      # Docker socket for container management
      - /var/run/docker.sock:/var/run/docker.sock:ro
      # CoreDNS config volume for writing allowlist
      - coredns-config:/etc/coredns
      # Static allowlist as fallback
      - ./configs/coredns/allowlist.hosts:/etc/coredns/static-allowlist.hosts:ro

    # No ports exposed - polling-based, outbound only
    networks:
      - infra-net

    restart: unless-stopped

  # ===========================================================================
  # FRP Client - Reverse tunnel for SSH access
  # Connects outbound to control plane FRP server
  # Optional: Only runs with --profile ssh
  # ===========================================================================
  frpc:
    image: snowdreamtech/frpc:latest
    container_name: frpc
    profiles:
      - ssh

    environment:
      - FRP_SERVER_ADDR=${FRP_SERVER_ADDR}
      - FRP_SERVER_PORT=${FRP_SERVER_PORT:-7000}
      - FRP_AUTH_TOKEN=${FRP_AUTH_TOKEN}
      - AGENT_ID=${AGENT_ID:-default}
      - FRP_REMOTE_PORT=${FRP_REMOTE_PORT:-6000}

    volumes:
      - ./configs/frpc/frpc.toml:/etc/frp/frpc.toml:ro

    # On BOTH networks:
    # - agent-net: to reach agent SSH (172.30.0.20:22)
    # - infra-net: to reach FRP server (outbound)
    networks:
      agent-net:
        ipv4_address: 172.30.0.30
      infra-net:
        ipv4_address: 172.31.0.30

    depends_on:
      - agent

    restart: unless-stopped

# =============================================================================
# Networks
# =============================================================================
networks:
  # Agent network - INTERNAL, no external access
  agent-net:
    driver: bridge
    internal: true  # No external connectivity
    enable_ipv6: false  # Prevent IPv6 bypass of egress controls
    ipam:
      config:
        - subnet: 172.30.0.0/16

  # Infrastructure network - can reach control plane
  infra-net:
    driver: bridge
    enable_ipv6: false  # Prevent IPv6 bypass of egress controls
    ipam:
      config:
        - subnet: 172.31.0.0/16

# =============================================================================
# Volumes
# =============================================================================
volumes:
  agent-logs:
  agent-workspace:
  coredns-config:
  vector-data:
  vector-backup:
